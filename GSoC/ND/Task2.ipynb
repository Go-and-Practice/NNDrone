{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "from scipy.stats import ks_2samp\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(signal_filename, backgorund_filename):\n",
    "    \"\"\"\n",
    "    :return: shuffled data\n",
    "    \"\"\"\n",
    "    sig_data = np.asarray(joblib.load(signal_filename))\n",
    "    bkg_data = np.asarray(joblib.load(backgorund_filename))\n",
    "    np.random.shuffle(sig_data)\n",
    "    np.random.shuffle(bkg_data)\n",
    "    return sig_data, bkg_data\n",
    "\n",
    "class Data:\n",
    "    def __init__(self, trainFraction, feature1_idx, feature2_idx, sigLabel=-1, bkgLabel=1, signal_filename='', backgorund_filename=''):\n",
    "        \"\"\"\n",
    "        :param trainFraction: float in (0,1)\n",
    "        :param feature1_idx: int in [0,5]\n",
    "        :param feature2_idx: int in [0,5]\n",
    "        :param sigLabel\n",
    "        :param bkgLabel\n",
    "        \"\"\"\n",
    "        sig_data, bkg_data = getData(signal_filename, backgorund_filename)\n",
    "        cutIndex = int(trainFraction * len(sig_data))\n",
    "        self._sigTrain = sig_data[: cutIndex,:]\n",
    "        np.random.shuffle(self._sigTrain)\n",
    "        self._sigTest = sig_data[cutIndex:,:]\n",
    "        self._bkgTrain = bkg_data[: cutIndex]\n",
    "        np.random.shuffle(self._bkgTrain)\n",
    "        self._bkgTest = bkg_data[cutIndex:,:]\n",
    "        self._sigLabel = sigLabel\n",
    "        self._bkgLabel = bkgLabel\n",
    "        self._feature1_idx = feature1_idx\n",
    "        self._feature2_idx = feature2_idx\n",
    "        \n",
    "    def set_feature_indexes(self, feature1_idx, feature2_idx):\n",
    "        self._feature1_idx = feature1_idx\n",
    "        self._feature2_idx = feature2_idx\n",
    "        \n",
    "    def shuffle(self):\n",
    "        np.random.shuffle(self._sigTrain)\n",
    "        np.random.shuffle(self._bkgTrain)\n",
    "        \n",
    "    def get_sigTrain(self):\n",
    "        return self._sigTrain[:, (self._feature1_idx, self._feature2_idx)]\n",
    "    \n",
    "    def get_sigTest(self):\n",
    "        return self._sigTest[:, (self._feature1_idx, self._feature2_idx)]\n",
    "        \n",
    "    def get_bkgTrain(self):\n",
    "        return self._bkgTrain[:, (self._feature1_idx, self._feature2_idx)]\n",
    "    \n",
    "    def get_bkgTest(self):\n",
    "        return self._bkgTest[:, (self._feature1_idx, self._feature2_idx)]\n",
    "    \n",
    "    def get_sigLabel(self):\n",
    "        return self._sigLabel\n",
    "    \n",
    "    def get_bkgLabel(self):\n",
    "        return self._bkgLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "        \n",
    "    @staticmethod\n",
    "    def train(hidden_layer_sizes, lr_init, dataObject, verbose):\n",
    "        \"\"\"\n",
    "        Trains a classifier\n",
    "        :param hidden_layer_sizes: tuple of zies: (100, 100)\n",
    "        :param lr_init: initial learning rate: 0.3\n",
    "        :return classifier\n",
    "        \"\"\"\n",
    "        mlp = MLPClassifier(activation='relu', alpha=1e-05, batch_size=200,\n",
    "                                   beta_1=0.9, beta_2=0.999, epsilon=1e-08,\n",
    "                                   hidden_layer_sizes=hidden_layer_sizes, learning_rate_init=lr_init,\n",
    "                                   random_state=1, shuffle=True, solver='adam', tol=0.00001,\n",
    "                                   early_stopping=False, validation_fraction=0.1,\n",
    "                                   verbose=verbose, warm_start=False)\n",
    "\n",
    "        X = np.append(dataObject.get_sigTrain(), dataObject.get_bkgTrain(), axis=0)\n",
    "        y = [dataObject.get_sigLabel()] * len(dataObject.get_sigTrain()) + [dataObject.get_bkgLabel()] * len(dataObject.get_bkgTrain())\n",
    "        mlp.fit(X, y)\n",
    "        return mlp\n",
    "\n",
    "    @staticmethod\n",
    "    def evaluate(classifier, dataObject, verbose):\n",
    "        \"\"\"\n",
    "        :param classifier: MLPClassifier\n",
    "        :return: test_accuracy\n",
    "        \"\"\"\n",
    "        \n",
    "        if len(dataObject.get_sigTrain()) != 0:\n",
    "            predictions = []\n",
    "            for entry in dataObject.get_sigTrain():\n",
    "                predictions.append(classifier.predict([entry])[0])\n",
    "            train_accuracy = predictions.count(dataObject.get_sigLabel()) / float(len(predictions))\n",
    "\n",
    "        predictions = []\n",
    "        for entry in dataObject.get_sigTest():\n",
    "            predictions.append(classifier.predict([entry])[0])\n",
    "        test_accuracy_sig = predictions.count(dataObject.get_sigLabel()) / float(len(predictions))\n",
    "\n",
    "        if verbose:\n",
    "            if len(dataObject.get_sigTrain()) != 0:\n",
    "                print \"Signal train accuracy: \" + str(train_accuracy)\n",
    "            print \"Signal test accuracy: \" + str(test_accuracy_sig)\n",
    "\n",
    "        if len(dataObject.get_bkgTrain()) != 0:\n",
    "            predictions = []\n",
    "            for entry in dataObject.get_bkgTrain():\n",
    "                predictions.append(classifier.predict([entry])[0])\n",
    "            train_accuracy = predictions.count(dataObject.get_bkgLabel()) / float(len(predictions))\n",
    "\n",
    "        predictions = []\n",
    "        for entry in dataObject.get_bkgTest():\n",
    "            predictions.append(classifier.predict([entry])[0])\n",
    "        test_accuracy_bkg = predictions.count(dataObject.get_bkgLabel()) / float(len(predictions))\n",
    "\n",
    "        if verbose:\n",
    "            if len(dataObject.get_bkgTrain()) != 0:\n",
    "                print \"Background train accuracy: \" + str(train_accuracy)\n",
    "            print \"Background test accuracy: \" + str(test_accuracy_bkg)\n",
    "\n",
    "        return (test_accuracy_bkg+test_accuracy_sig) / 2\n",
    "    \n",
    "    @staticmethod\n",
    "    def predict_test_data(classifier, dataObject, verbose):\n",
    "        \"\"\"\n",
    "        :param classifier: MLPClassifier\n",
    "        :return: test_accuracy\n",
    "        \"\"\"\n",
    "        \n",
    "        testSample = []\n",
    "        predictions_signal = []\n",
    "        for entry in dataObject.get_sigTest():\n",
    "            probability = float(classifier.predict_proba([entry])[0][0])\n",
    "            predictions_signal.append(classifier.predict([entry])[0])\n",
    "            testSample.append(probability)\n",
    "        test_accuracy_sig = predictions_signal.count(dataObject.get_sigLabel()) / float(len(predictions_signal))\n",
    "\n",
    "        if verbose:\n",
    "            print \"Signal test accuracy: \" + str(test_accuracy_sig)\n",
    "\n",
    "        testSample = []\n",
    "        predictions_background = []\n",
    "        for entry in dataObject.get_bkgTest():\n",
    "            probability = float(classifier.predict_proba([entry])[0][0])\n",
    "            predictions_background.append(classifier.predict([entry])[0])\n",
    "            testSample.append(probability)\n",
    "        test_accuracy_bkg = predictions_background.count(dataObject.get_bkgLabel()) / float(len(predictions_background))\n",
    "\n",
    "        if verbose:\n",
    "            print \"Background test accuracy: \" + str(test_accuracy_bkg)\n",
    "\n",
    "        return (test_accuracy_bkg+test_accuracy_sig) / 2, predictions_signal, dataObject._sigTest, predictions_background, dataObject._bkgTest\n",
    "    \n",
    "    @staticmethod\n",
    "    def saveClassifier(classifier, filename):\n",
    "        joblib.dump(classifier, filename )\n",
    "        print 'Classifier saved to file'\n",
    "    \n",
    "    @staticmethod\n",
    "    def loadClassifier(filename):\n",
    "        classifier = joblib.load(filename )\n",
    "        return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_N(N, layer_sizes, lr_init, dataObject, verbose):\n",
    "    accuracy_setting_history = []\n",
    "    for _ in range(N):\n",
    "        classifier = Trainer.train(layer_sizes,lr_init, dataObject, verbose)\n",
    "        accuracy = Trainer.evaluate(classifier, dataObject, verbose)\n",
    "        accuracy_setting_history.append(accuracy)\n",
    "\n",
    "    candidate = sum(accuracy_setting_history)/N\n",
    "    return classifier, candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_search():\n",
    "    trainFraction_ = 0.5\n",
    "    hidden_layer_sizes_ = (100, 100)\n",
    "    lr_init_ = 0.3\n",
    "\n",
    "    histories_indexes_ = []\n",
    "    best_average_accuracy_ = 0\n",
    "    best_feature1_idx_ = -1\n",
    "    best_feature2_idx_ = -1\n",
    "\n",
    "    dataObject_ = Data(trainFraction_, best_feature1_idx_, best_feature2_idx_)\n",
    "    \n",
    "    for feature1_idx_ in range(6):\n",
    "        for feature2_idx_ in range(feature1_idx_+1, 6):\n",
    "\n",
    "            dataObject_.set_feature_indexes(feature1_idx_, feature2_idx_)\n",
    "            _, candidate_ = train_N(1, hidden_layer_sizes_, lr_init_, dataObject_, verbose=False)\n",
    "            dataObject_.shuffle()\n",
    "            if candidate_ > best_average_accuracy_:\n",
    "                best_average_accuracy_ = candidate_\n",
    "                best_feature1_idx_ = feature1_idx_\n",
    "                best_feature2_idx_ = feature2_idx_\n",
    "\n",
    "            histories_indexes_.append([feature1_idx_, feature2_idx_, candidate_])\n",
    "    \n",
    "    #print \"(feature1, feature2, AP)\"\n",
    "    #print histories_indexes_\n",
    "    print \"Best feature indexes \"+ str(best_feature1_idx_) + \" \" + str(best_feature2_idx_)\n",
    "    #print \"Best accuracy \" + str(best_average_accuracy_)\n",
    "    \n",
    "    network_dims_ = [(200, 200), (10,10), (20,20,20,20), (100, 40, 20, 10), ]\n",
    "\n",
    "    histories_hidden_sizes_ = []\n",
    "    best_sizes_ = None\n",
    "    best_average_accuracy_ = 0\n",
    "\n",
    "    dataObject_.set_feature_indexes(best_feature1_idx_, best_feature2_idx_)\n",
    "\n",
    "    for hidden_sizes_ in network_dims_:\n",
    "\n",
    "        _, candidate_ = train_N(1, hidden_sizes_, lr_init_, dataObject_, verbose=False)\n",
    "        dataObject_.shuffle()\n",
    "        if candidate_ > best_average_accuracy_:\n",
    "            best_average_accuracy_ = candidate_\n",
    "            best_sizes_ = hidden_sizes_\n",
    "\n",
    "        histories_hidden_sizes_.append([hidden_sizes_, candidate_])\n",
    "    \n",
    "    #print \"((hidden layer sizes), AP)\"\n",
    "    #print histories_hidden_sizes_\n",
    "    print \"Best hidden layer size \" + str(best_sizes_)\n",
    "    \n",
    "    return best_feature1_idx_, best_feature2_idx_, best_sizes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Training a Input Model ( Neural Network that is taught on the signal )\n",
    "## Skip following 3 cells if you don't wanna train and search hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best feature indexes 2 3\n",
      "Best hidden layer size (200, 200)\n"
     ]
    }
   ],
   "source": [
    "best_feature1_idx_, best_feature2_idx_, best_sizes_ = hyperparameter_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, (200, 200))\n"
     ]
    }
   ],
   "source": [
    "print (best_feature1_idx_, best_feature2_idx_, best_sizes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model accuracy: 0.8962\n",
      "Classifier saved to file\n"
     ]
    }
   ],
   "source": [
    "def save_best_model(best_feature1_idx_, best_feature2_idx_, best_sizes_):\n",
    "    dataObject_ = Data(trainFraction_, best_feature1_idx_, best_feature2_idx_)\n",
    "    dataObject_.set_feature_indexes(best_feature1_idx_, best_feature2_idx_)\n",
    "    best_classifier_ = Trainer.train(best_sizes_, lr_init_, dataObject_, verbose=False)\n",
    "    best_accuracy_ = Trainer.evaluate(best_classifier_, dataObject_, verbose=False)\n",
    "    print \"Best model accuracy: \" + str(best_accuracy_)\n",
    "    Trainer.saveClassifier(best_classifier_,'best_classifier2.pkl')\n",
    "save_best_model(best_feature1_idx_, best_feature2_idx_, best_sizes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run from here if you want to evaluate best model on new data with the same format \n",
    "### the filenames with filepaths should be sent as parameters: signal file path, background file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_best_classifier_on_new_data(signal_filename, backgorund_filename, classifier_filename):\n",
    "    dataObject_ = Data(trainFraction=0, feature1_idx=2, feature2_idx=3, signal_filename=signal_filename, backgorund_filename=backgorund_filename)\n",
    "    loaded_class_ = Trainer.loadClassifier(classifier_filename)\n",
    "    accuracy_ = Trainer.evaluate(loaded_class_, dataObject_, verbose=True)\n",
    "    print \"Accuracy: \"+str(accuracy_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal test accuracy: 0.9038\n",
      "Background test accuracy: 0.8879\n",
      "Accuracy: 0.89585\n"
     ]
    }
   ],
   "source": [
    "evaluate_best_classifier_on_new_data('./HEPDrone/data/signal_data.p', './HEPDrone/data/background_data.p', 'best_classifier2.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
