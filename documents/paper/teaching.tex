\section{Drone learning}
\label{sec:dlearn}

The training of the drone network requires that the original network is
extensively probed in the parameter space in which accuracy is desired.
The principle utilised in the training of the drone is that sufficient
approximation of the original network is achieved with sufficient expansion
of the hyperparameter space of the drone, and that the same global minimum
of the loss function can be found, as reported in Ref.~\cite{losssurfaces}.
The ability of a neural network with a continuous, bounded, non-constant activation
function to approximate functions to an arbitrary degree has been indeed known
since the early 1990s~\cite{HORNIK1991251}.

\subsection{Initial drone structure and corresponding training}

The drone chosen for use in this article is initialised as a
neural network with a single intermediate (hidden) layer of 5
nodes using a standard sigmoid activation function. The network
has the number of inputs determined from the number of desired
characteristics of the decay signature. A single output is taken
from the network and a linear model is used to relate layers.

The model is made to approximate the original classifier through
a supervised learning technique, though not in the traditional sense.
Instead of a label as {\tt signal} or {\tt background} taken from the training data, the
output of the original classifier is used as a label. This means that the
loss function is defined as
\begin{align}
\mathcal{L} = \sum_i \left( F(\vec{x}_i) - G_i(\vec{x}_i) \right)^2,
\end{align}
where $F(\vec{x}_i)$ and $G(\vec{x}_i)$ are the outputs
of the original and drone models on datapoint
$i$ of the mini-batch, respectively. The advantage of such a loss function is per-event
equivalence of the original and drone model, in addition to equivalence
of performance. For the drone training detailed in this article, standard
mini-batch stochastic gradient descent is used. A feature of this method
is that the drone classifier does not see the labels of the training data,
but rather learns the same properties from the original classifier.
This is therefore a neural network that learns from another neural network in an
empirical manner.

\subsection{Model morphing during the learning phase}

In order to keep the hyperparameter space to the minimum required level,
additional degrees of freedom are added only when required.
This removes the possibility of choosing an incorrect size of the
drone network. During the learning phase, the following conditions are required
to trigger the extension of the hidden layer in the $j^{\rm th}$ epoch:
\begin{align}
\delta_{j} &\equiv |\mathcal{L}_j-\mathcal{L}_{j-1}|/\mathcal{L}_j < \kappa,\label{eq:cond1}\\
\sigma_{j} &\equiv m (1 - e^{-b(\hat{t} + n)})\delta_{j}\mathcal{L}_j \nonumber\\
\mathcal{L}_j &< \hat{\mathcal{L}} - \sigma_{j} \label{eq:cond2},
\end{align}
where $\kappa$ is the required threshold, $\sigma$ is the required minimum improvement
of the loss function and $\hat{\mathcal{L}}$ is the value of the loss function when
the hidden layer was last extended. The required improvement starts from a minimum at $n$,
increases with epoch number after previous extension $\hat{t}$ and steepness $b$
until a maximum at $m$. The precise values of the parameters
$\kappa$, $n$, $m$, $b$ are not of particular importance. Rather, the topology described by
eqs.~\ref{eq:cond1} and \ref{eq:cond2} is crucial. The relative loss function improvement,
$\delta_{j}$, can never realistically be larger than $1$ and the limit, $\kappa$, at which
no significant improvement occurs is acceptably set at 0.02 (smaller than $2\sigma$
standard deviations). The descent in loss space, $\hat{\mathcal{L}} - \mathcal{L}_j$,
is further required to be significantly large, minimizing the chance of getting stuck in
isolated local minima. The function, $\sigma_{j}$, is chosen to increase this requirement
with each epoch for two reasons - it is bounded and can approach its asymptote arbitrarily fast.
It scales $\delta_{j}$ such that the loss descent must be significant
before an update is triggered. Since $\delta_{j}$ is expected to decrease with epoch number,
the minumum and maximum values of $\sigma_{j}$ are chosen as such:
\begin{align}
\sigma_{j}(\hat{t} = 0) &\equiv min(\sigma_{j}) \equiv 2.5\delta_{j}\mathcal{L}_j \implies 5\sigma ~\text{std.dev.} \\
\sigma_{j}(\hat{t} = \infty) &\equiv min(\sigma_{j}) \equiv 25\delta_{j}\mathcal{L}_j \implies 50\sigma ~\text{std.dev.}
\end{align}
The steepness, $b$, is chosen such that the transition from the minimum to maximum takes
on average 50 epochs. This ensures a change cannot be triggered immediately
after a previous one and the learning can still proceed if more freedom is indeed required.
Also, it allows the network to stabilize after a big change.

When the conditions in eqs.~\ref{eq:cond1} and \ref{eq:cond2} are met, the linear model
is updated to extend the weights matrices and bias vectors
to accommodate the layer addition.
The associated neurons are initialised with a zero weight
to ensure continuity of the loss function value.
