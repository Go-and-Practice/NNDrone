{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading signal data file...\n",
      "Loading background data file...\n"
     ]
    }
   ],
   "source": [
    "from ROOT import TH1F, TCanvas, gStyle, TLegend, TGraph\n",
    "from sklearn.externals import joblib\n",
    "from array import array\n",
    "import pickle\n",
    "from scipy.stats import ks_2samp\n",
    "import numpy as np\n",
    "import datetime\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import LocallyConnected1D\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.externals import joblib\n",
    "from keras.models import load_model\n",
    "from nndrone.converters import BasicConverter\n",
    "from nndrone.models import BaseModel\n",
    "import os.path\n",
    "\n",
    "trainFraction = 0.5\n",
    "\n",
    "# load data\n",
    "print ('Loading signal data file...')\n",
    "sig_data = joblib.load('../../data/signal_data.p')\n",
    "print ('Loading background data file...')\n",
    "bkg_data = joblib.load('../../data/background_data.p')\n",
    "#\n",
    "cutIndex = int(trainFraction * len(sig_data))\n",
    "#\n",
    "sigTrain = sig_data[: cutIndex]\n",
    "sigTest = sig_data[cutIndex:]\n",
    "#\n",
    "bgTrain = bkg_data[: cutIndex]\n",
    "bgTest = bkg_data[cutIndex:]\n",
    "\n",
    "# Load classifier and scaler\n",
    "scaler = joblib.load('scaler_Bexample.pkl')\n",
    "classifier = load_model('classifier_Bexample.h5')\n",
    "\n",
    "# transform the training sameple\n",
    "sigTrain = scaler.transform(sigTrain)\n",
    "# do the same to the test data\n",
    "sigTest = scaler.transform(sigTest)\n",
    "# do the same to the test data\n",
    "bgTrain = scaler.transform(bgTrain)\n",
    "# do the same to the test data\n",
    "bgTest = scaler.transform(bgTest)\n",
    "\n",
    "train = np.append(sigTrain, bgTrain, axis=0)\n",
    "target = [1] * len(sigTrain) + [0] * len(bgTrain)\n",
    "test = np.append(sigTest, bgTest, axis=0)\n",
    "target_test = [1] * len(sigTest) + [0] * len(bgTest)\n",
    "#train = np.expand_dims(train.reshape(1, -1), axis=2)\n",
    "#test = np.expand_dims(test.reshape(1, -1), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModel: Adding layer...\n",
      "BaseModel: Adding weights matrix: (5,6)\n",
      "BaseModel: Adding bias vector: (5,1)\n",
      "BaseModel: Adding layer...\n",
      "BaseModel: Adding weights matrix: (1,5)\n",
      "BaseModel: Adding bias vector: (1,1)\n",
      "Layer 1\n",
      "Weights matrix shape: (5,6)\n",
      "Bias vector shape (5,1)\n",
      "Layer 2\n",
      "Weights matrix shape: (1,5)\n",
      "Bias vector shape (1,1)\n",
      "Starting stochastic conversion...\n",
      "Epoch: 0, loss 0.1107852921917279, diff 0.00000, last updated loss 1000.00000\n",
      "Epoch: 1, loss 0.027059986944951674, diff 3.09406, last updated loss 1000.00000\n",
      "Epoch: 2, loss 0.017880999414483567, diff 0.51334, last updated loss 1000.00000\n",
      "Epoch: 3, loss 0.014846109303444143, diff 0.20442, last updated loss 1000.00000\n",
      "Epoch: 4, loss 0.013322504657982822, diff 0.11436, last updated loss 1000.00000\n",
      "Epoch: 5, loss 0.012420200131011002, diff 0.07265, last updated loss 1000.00000\n",
      "Epoch: 6, loss 0.011830508074108502, diff 0.04985, last updated loss 1000.00000\n",
      "Epoch: 7, loss 0.011418747104416562, diff 0.03606, last updated loss 1000.00000\n",
      "Epoch: 8, loss 0.011117569205517546, diff 0.02709, last updated loss 1000.00000\n",
      "Epoch: 9, loss 0.010889347586805312, diff 0.02096, last updated loss 1000.00000\n",
      "Model conversion not sufficient, updating...\n",
      "Last updated loss: 1000.0\n",
      "Model structure is now:\n",
      "Layer 1\n",
      "Weights matrix shape: (6,6)\n",
      "Bias vector shape (6,1)\n",
      "Layer 2\n",
      "Weights matrix shape: (1,6)\n",
      "Bias vector shape (1,1)\n",
      "Epoch: 10, loss 0.010711166408514083, diff 0.01664, last updated loss 0.01071\n",
      "Epoch: 11, loss 0.01056869188431922, diff 0.01348, last updated loss 0.01071\n",
      "Epoch: 12, loss 0.010448125185004124, diff 0.01154, last updated loss 0.01071\n",
      "Epoch: 13, loss 0.010346293873400837, diff 0.00984, last updated loss 0.01071\n",
      "Epoch: 14, loss 0.010257789742195683, diff 0.00863, last updated loss 0.01071\n",
      "Epoch: 15, loss 0.010178433867862753, diff 0.00780, last updated loss 0.01071\n",
      "Epoch: 16, loss 0.01010496559007864, diff 0.00727, last updated loss 0.01071\n",
      "Epoch: 17, loss 0.010034764692355725, diff 0.00700, last updated loss 0.01071\n",
      "Epoch: 18, loss 0.009965668936872339, diff 0.00693, last updated loss 0.01071\n",
      "Epoch: 19, loss 0.009895869386333911, diff 0.00705, last updated loss 0.01071\n",
      "Epoch: 20, loss 0.009823860489203527, diff 0.00733, last updated loss 0.01071\n",
      "Epoch: 21, loss 0.009748419549872434, diff 0.00774, last updated loss 0.01071\n",
      "Epoch: 22, loss 0.009668585961115571, diff 0.00826, last updated loss 0.01071\n",
      "Epoch: 23, loss 0.00958361396194703, diff 0.00887, last updated loss 0.01071\n",
      "Epoch: 24, loss 0.009492891269163214, diff 0.00956, last updated loss 0.01071\n",
      "Epoch: 25, loss 0.00939584279959004, diff 0.01033, last updated loss 0.01071\n",
      "Epoch: 26, loss 0.009291853925565636, diff 0.01119, last updated loss 0.01071\n",
      "Epoch: 27, loss 0.009180239529610265, diff 0.01216, last updated loss 0.01071\n",
      "Epoch: 28, loss 0.009060264801405258, diff 0.01324, last updated loss 0.01071\n",
      "Epoch: 29, loss 0.008931211970805746, diff 0.01445, last updated loss 0.01071\n",
      "Epoch: 30, loss 0.008792492209612014, diff 0.01578, last updated loss 0.01071\n",
      "Epoch: 31, loss 0.008643815175000522, diff 0.01720, last updated loss 0.01071\n",
      "Epoch: 32, loss 0.00848543072157577, diff 0.01867, last updated loss 0.01071\n",
      "Epoch: 33, loss 0.008318418746797713, diff 0.02008, last updated loss 0.01071\n",
      "Epoch: 34, loss 0.008144896853168694, diff 0.02130, last updated loss 0.01071\n",
      "Epoch: 35, loss 0.007967890584829095, diff 0.02221, last updated loss 0.01071\n",
      "Epoch: 36, loss 0.007790685442590201, diff 0.02275, last updated loss 0.01071\n",
      "Epoch: 37, loss 0.007615917670631224, diff 0.02295, last updated loss 0.01071\n",
      "Epoch: 38, loss 0.007445024790673521, diff 0.02295, last updated loss 0.01071\n",
      "Epoch: 39, loss 0.007278343968191849, diff 0.02290, last updated loss 0.01071\n",
      "Epoch: 40, loss 0.007115540833569366, diff 0.02288, last updated loss 0.01071\n",
      "Epoch: 41, loss 0.006955970466769565, diff 0.02294, last updated loss 0.01071\n",
      "Epoch: 42, loss 0.006798850841392264, diff 0.02311, last updated loss 0.01071\n",
      "Epoch: 43, loss 0.0066432972257424285, diff 0.02342, last updated loss 0.01071\n",
      "Epoch: 44, loss 0.006488284107238529, diff 0.02389, last updated loss 0.01071\n",
      "Epoch: 45, loss 0.006332594793120517, diff 0.02459, last updated loss 0.01071\n",
      "Epoch: 46, loss 0.006174837754119106, diff 0.02555, last updated loss 0.01071\n",
      "Epoch: 47, loss 0.006013632878555926, diff 0.02681, last updated loss 0.01071\n",
      "Epoch: 48, loss 0.005848024914553347, diff 0.02832, last updated loss 0.01071\n",
      "Epoch: 49, loss 0.0056779747816771975, diff 0.02995, last updated loss 0.01071\n",
      "Epoch: 50, loss 0.005504528954715537, diff 0.03151, last updated loss 0.01071\n",
      "Epoch: 51, loss 0.005329417365543533, diff 0.03286, last updated loss 0.01071\n",
      "Epoch: 52, loss 0.005154411558186114, diff 0.03395, last updated loss 0.01071\n",
      "Epoch: 53, loss 0.004980960478388701, diff 0.03482, last updated loss 0.01071\n",
      "Epoch: 54, loss 0.004810180081223316, diff 0.03550, last updated loss 0.01071\n",
      "Epoch: 55, loss 0.004642961023795012, diff 0.03602, last updated loss 0.01071\n",
      "Epoch: 56, loss 0.004480038601219179, diff 0.03637, last updated loss 0.01071\n",
      "Epoch: 57, loss 0.004322014061994483, diff 0.03656, last updated loss 0.01071\n",
      "Epoch: 58, loss 0.004169359880409234, diff 0.03661, last updated loss 0.01071\n",
      "Epoch: 59, loss 0.004022428105386177, diff 0.03653, last updated loss 0.01071\n",
      "Epoch: 60, loss 0.0038814643802142536, diff 0.03632, last updated loss 0.01071\n",
      "Epoch: 61, loss 0.003746624038717338, diff 0.03599, last updated loss 0.01071\n",
      "Epoch: 62, loss 0.003617986902774652, diff 0.03555, last updated loss 0.01071\n",
      "Epoch: 63, loss 0.0034955692735414317, diff 0.03502, last updated loss 0.01071\n",
      "Epoch: 64, loss 0.0033793330578709415, diff 0.03440, last updated loss 0.01071\n",
      "Epoch: 65, loss 0.003269192678143209, diff 0.03369, last updated loss 0.01071\n",
      "Epoch: 66, loss 0.0031650206168003475, diff 0.03291, last updated loss 0.01071\n",
      "Epoch: 67, loss 0.0030666523906119902, diff 0.03208, last updated loss 0.01071\n",
      "Epoch: 68, loss 0.0029738915619388785, diff 0.03119, last updated loss 0.01071\n",
      "Epoch: 69, loss 0.0028865151337695407, diff 0.03027, last updated loss 0.01071\n",
      "Epoch: 70, loss 0.002804279392732982, diff 0.02933, last updated loss 0.01071\n",
      "Epoch: 71, loss 0.0027269260211364014, diff 0.02837, last updated loss 0.01071\n",
      "Epoch: 72, loss 0.0026541881495020935, diff 0.02740, last updated loss 0.01071\n",
      "Epoch: 73, loss 0.00258579598691594, diff 0.02645, last updated loss 0.01071\n",
      "Epoch: 74, loss 0.0025214817300744, diff 0.02551, last updated loss 0.01071\n",
      "Epoch: 75, loss 0.0024609835701323492, diff 0.02458, last updated loss 0.01071\n",
      "Epoch: 76, loss 0.0024040487433002163, diff 0.02368, last updated loss 0.01071\n",
      "Epoch: 77, loss 0.002350435674340259, diff 0.02281, last updated loss 0.01071\n",
      "Epoch: 78, loss 0.0022999153281703373, diff 0.02197, last updated loss 0.01071\n",
      "Epoch: 79, loss 0.0022522719150618064, diff 0.02115, last updated loss 0.01071\n",
      "Epoch: 80, loss 0.0022073030984574656, diff 0.02037, last updated loss 0.01071\n",
      "Model conversion not sufficient, updating...\n",
      "Last updated loss: 0.010711166408514083\n",
      "Model structure is now:\n",
      "Layer 1\n",
      "Weights matrix shape: (7,6)\n",
      "Bias vector shape (7,1)\n",
      "Layer 2\n",
      "Weights matrix shape: (1,7)\n",
      "Bias vector shape (1,1)\n",
      "Epoch: 81, loss 0.002164819841772696, diff 0.01962, last updated loss 0.00216\n",
      "Epoch: 82, loss 0.0021245440902194746, diff 0.01896, last updated loss 0.00216\n",
      "Epoch: 83, loss 0.0020858696418473953, diff 0.01854, last updated loss 0.00216\n",
      "Epoch: 84, loss 0.002049200142373304, diff 0.01789, last updated loss 0.00216\n",
      "Epoch: 85, loss 0.0020144541369316337, diff 0.01725, last updated loss 0.00216\n",
      "Epoch: 86, loss 0.0019814953770215787, diff 0.01663, last updated loss 0.00216\n",
      "Epoch: 87, loss 0.001950197017783911, diff 0.01605, last updated loss 0.00216\n",
      "Epoch: 88, loss 0.0019204418117373134, diff 0.01549, last updated loss 0.00216\n",
      "Epoch: 89, loss 0.0018921216731724979, diff 0.01497, last updated loss 0.00216\n",
      "Epoch: 90, loss 0.0018651371275735624, diff 0.01447, last updated loss 0.00216\n",
      "Epoch: 91, loss 0.0018393967506488366, diff 0.01399, last updated loss 0.00216\n",
      "Epoch: 92, loss 0.001814816619056136, diff 0.01354, last updated loss 0.00216\n",
      "Epoch: 93, loss 0.001791319774096643, diff 0.01312, last updated loss 0.00216\n",
      "Epoch: 94, loss 0.001768835696238623, diff 0.01271, last updated loss 0.00216\n",
      "Epoch: 95, loss 0.0017472997899595285, diff 0.01233, last updated loss 0.00216\n",
      "Epoch: 96, loss 0.0017266528810529326, diff 0.01196, last updated loss 0.00216\n",
      "Epoch: 97, loss 0.0017068407307648421, diff 0.01161, last updated loss 0.00216\n",
      "Model conversion not sufficient, updating...\n",
      "Last updated loss: 0.002164819841772696\n",
      "Model structure is now:\n",
      "Layer 1\n",
      "Weights matrix shape: (8,6)\n",
      "Bias vector shape (8,1)\n",
      "Layer 2\n",
      "Weights matrix shape: (1,8)\n",
      "Bias vector shape (1,1)\n",
      "Epoch: 98, loss 0.0016878135723626968, diff 0.01127, last updated loss 0.00169\n",
      "Epoch: 99, loss 0.0016696866770942614, diff 0.01086, last updated loss 0.00169\n",
      "Epoch: 100, loss 0.0016518947063682823, diff 0.01077, last updated loss 0.00169\n",
      "Epoch: 101, loss 0.00163474089344255, diff 0.01049, last updated loss 0.00169\n",
      "Epoch: 102, loss 0.0016182337373286029, diff 0.01020, last updated loss 0.00169\n",
      "Epoch: 103, loss 0.0016023380902916752, diff 0.00992, last updated loss 0.00169\n",
      "Epoch: 104, loss 0.001587020931046692, diff 0.00965, last updated loss 0.00169\n",
      "Epoch: 105, loss 0.0015722515004857618, diff 0.00939, last updated loss 0.00169\n",
      "Epoch: 106, loss 0.0015580011959091936, diff 0.00915, last updated loss 0.00169\n",
      "Epoch: 107, loss 0.0015442434192781175, diff 0.00891, last updated loss 0.00169\n",
      "Epoch: 108, loss 0.001530953422963755, diff 0.00868, last updated loss 0.00169\n",
      "Epoch: 109, loss 0.0015181081658132277, diff 0.00846, last updated loss 0.00169\n",
      "Epoch: 110, loss 0.0015056861819569012, diff 0.00825, last updated loss 0.00169\n",
      "Epoch: 111, loss 0.0014936674614258036, diff 0.00805, last updated loss 0.00169\n",
      "Epoch: 112, loss 0.001482033340818507, diff 0.00785, last updated loss 0.00169\n",
      "Epoch: 113, loss 0.0014707664023042612, diff 0.00766, last updated loss 0.00169\n",
      "Epoch: 114, loss 0.0014598503795594973, diff 0.00748, last updated loss 0.00169\n",
      "Epoch: 115, loss 0.001449270069581781, diff 0.00730, last updated loss 0.00169\n",
      "Epoch: 116, loss 0.0014390112496335547, diff 0.00713, last updated loss 0.00169\n",
      "Epoch: 117, loss 0.0014290605988187721, diff 0.00696, last updated loss 0.00169\n",
      "Model conversion not sufficient, updating...\n",
      "Last updated loss: 0.0016878135723626968\n",
      "Model structure is now:\n",
      "Layer 1\n",
      "Weights matrix shape: (9,6)\n",
      "Bias vector shape (9,1)\n",
      "Layer 2\n",
      "Weights matrix shape: (1,9)\n",
      "Bias vector shape (1,1)\n",
      "Epoch: 118, loss 0.0014194056239906206, diff 0.00680, last updated loss 0.00142\n",
      "Epoch: 119, loss 0.0014102799366550328, diff 0.00647, last updated loss 0.00142\n",
      "Epoch: 120, loss 0.0014011347184436872, diff 0.00653, last updated loss 0.00142\n",
      "Epoch: 121, loss 0.0013922196424732097, diff 0.00640, last updated loss 0.00142\n",
      "Epoch: 122, loss 0.0013835639500504174, diff 0.00626, last updated loss 0.00142\n",
      "Epoch: 123, loss 0.0013751575464064111, diff 0.00611, last updated loss 0.00142\n",
      "Epoch: 124, loss 0.0013669909192857857, diff 0.00597, last updated loss 0.00142\n",
      "Epoch: 125, loss 0.0013590550659958885, diff 0.00584, last updated loss 0.00142\n",
      "Epoch: 126, loss 0.0013513414377305285, diff 0.00571, last updated loss 0.00142\n",
      "Epoch: 127, loss 0.0013438418954447038, diff 0.00558, last updated loss 0.00142\n",
      "Epoch: 128, loss 0.0013365486707802418, diff 0.00546, last updated loss 0.00142\n",
      "Epoch: 129, loss 0.0013294543314743077, diff 0.00534, last updated loss 0.00142\n",
      "Epoch: 130, loss 0.0013225517511356781, diff 0.00522, last updated loss 0.00142\n",
      "Epoch: 131, loss 0.0013158340830968214, diff 0.00511, last updated loss 0.00142\n",
      "Epoch: 132, loss 0.001309294737921413, diff 0.00499, last updated loss 0.00142\n",
      "Epoch: 133, loss 0.001302927364097577, diff 0.00489, last updated loss 0.00142\n",
      "Epoch: 134, loss 0.0012967258314459705, diff 0.00478, last updated loss 0.00142\n",
      "Epoch: 135, loss 0.001290684216797041, diff 0.00468, last updated loss 0.00142\n",
      "Epoch: 136, loss 0.001284796791531481, diff 0.00458, last updated loss 0.00142\n",
      "Epoch: 137, loss 0.001279058010624609, diff 0.00449, last updated loss 0.00142\n",
      "Epoch: 138, loss 0.0012734625028860214, diff 0.00439, last updated loss 0.00142\n",
      "Epoch: 139, loss 0.0012680050621360322, diff 0.00430, last updated loss 0.00142\n",
      "Model conversion not sufficient, updating...\n",
      "Last updated loss: 0.0014194056239906206\n",
      "Model structure is now:\n",
      "Layer 1\n",
      "Weights matrix shape: (10,6)\n",
      "Bias vector shape (10,1)\n",
      "Layer 2\n",
      "Weights matrix shape: (1,10)\n",
      "Bias vector shape (1,1)\n",
      "Epoch: 140, loss 0.0012626806391083773, diff 0.00422, last updated loss 0.00126\n",
      "Epoch: 141, loss 0.0012577427828648101, diff 0.00393, last updated loss 0.00126\n",
      "Epoch: 142, loss 0.0012526617149599306, diff 0.00406, last updated loss 0.00126\n",
      "Epoch: 143, loss 0.001247667855147342, diff 0.00400, last updated loss 0.00126\n",
      "Epoch: 144, loss 0.0012427904109864724, diff 0.00392, last updated loss 0.00126\n",
      "Epoch: 145, loss 0.0012380246138114714, diff 0.00385, last updated loss 0.00126\n",
      "Epoch: 146, loss 0.001233365973818422, diff 0.00378, last updated loss 0.00126\n",
      "Epoch: 147, loss 0.0012288101746916347, diff 0.00371, last updated loss 0.00126\n",
      "Epoch: 148, loss 0.0012243530347268836, diff 0.00364, last updated loss 0.00126\n",
      "Epoch: 149, loss 0.0012199904911451703, diff 0.00358, last updated loss 0.00126\n",
      "Epoch: 150, loss 0.0012157185905560558, diff 0.00351, last updated loss 0.00126\n",
      "Epoch: 151, loss 0.0012115334816005, diff 0.00345, last updated loss 0.00126\n",
      "Epoch: 152, loss 0.0012074314087126442, diff 0.00340, last updated loss 0.00126\n",
      "Epoch: 153, loss 0.0012034087066640855, diff 0.00334, last updated loss 0.00126\n",
      "Epoch: 154, loss 0.0011994617957681263, diff 0.00329, last updated loss 0.00126\n",
      "Epoch: 155, loss 0.0011955871776977173, diff 0.00324, last updated loss 0.00126\n",
      "Epoch: 156, loss 0.0011917814319035325, diff 0.00319, last updated loss 0.00126\n",
      "Epoch: 157, loss 0.001188041212634445, diff 0.00315, last updated loss 0.00126\n",
      "Epoch: 158, loss 0.0011843632465714223, diff 0.00311, last updated loss 0.00126\n",
      "Epoch: 159, loss 0.001180744331090473, diff 0.00306, last updated loss 0.00126\n",
      "Epoch: 160, loss 0.0011771813331723346, diff 0.00303, last updated loss 0.00126\n",
      "Epoch: 161, loss 0.001173671188976761, diff 0.00299, last updated loss 0.00126\n",
      "Epoch: 162, loss 0.0011702109040976506, diff 0.00296, last updated loss 0.00126\n",
      "Epoch: 163, loss 0.001166797554512023, diff 0.00293, last updated loss 0.00126\n",
      "Epoch: 164, loss 0.0011634282882308706, diff 0.00290, last updated loss 0.00126\n",
      "Epoch: 165, loss 0.001160100327653576, diff 0.00287, last updated loss 0.00126\n",
      "Epoch: 166, loss 0.0011568109726188898, diff 0.00284, last updated loss 0.00126\n",
      "Model conversion not sufficient, updating...\n",
      "Last updated loss: 0.0012626806391083773\n",
      "Model structure is now:\n",
      "Layer 1\n",
      "Weights matrix shape: (11,6)\n",
      "Bias vector shape (11,1)\n",
      "Layer 2\n",
      "Weights matrix shape: (1,11)\n",
      "Bias vector shape (1,1)\n",
      "Epoch: 167, loss 0.001153557604135524, diff 0.00282, last updated loss 0.00115\n",
      "Epoch: 168, loss 0.0011505876576886447, diff 0.00258, last updated loss 0.00115\n",
      "Epoch: 169, loss 0.0011473972486944865, diff 0.00278, last updated loss 0.00115\n",
      "Epoch: 170, loss 0.001144210264044845, diff 0.00279, last updated loss 0.00115\n",
      "Epoch: 171, loss 0.0011410506334307295, diff 0.00277, last updated loss 0.00115\n",
      "Epoch: 172, loss 0.0011379159921300255, diff 0.00275, last updated loss 0.00115\n",
      "Epoch: 173, loss 0.0011348042269774179, diff 0.00274, last updated loss 0.00115\n",
      "Epoch: 174, loss 0.0011317133944914592, diff 0.00273, last updated loss 0.00115\n",
      "Epoch: 175, loss 0.0011286416984235793, diff 0.00272, last updated loss 0.00115\n",
      "Epoch: 176, loss 0.0011255874885818709, diff 0.00271, last updated loss 0.00115\n",
      "Epoch: 177, loss 0.0011225492644151003, diff 0.00271, last updated loss 0.00115\n",
      "Epoch: 178, loss 0.0011195256794742712, diff 0.00270, last updated loss 0.00115\n",
      "Epoch: 179, loss 0.0011165155456416202, diff 0.00270, last updated loss 0.00115\n",
      "Epoch: 180, loss 0.001113517836670582, diff 0.00269, last updated loss 0.00115\n",
      "Epoch: 181, loss 0.0011105316907641437, diff 0.00269, last updated loss 0.00115\n",
      "Epoch: 182, loss 0.0011075564119891336, diff 0.00269, last updated loss 0.00115\n",
      "Epoch: 183, loss 0.0011045914703659402, diff 0.00268, last updated loss 0.00115\n",
      "Epoch: 184, loss 0.001101636500509516, diff 0.00268, last updated loss 0.00115\n",
      "Epoch: 185, loss 0.0010986912987344293, diff 0.00268, last updated loss 0.00115\n",
      "Epoch: 186, loss 0.00109575581857652, diff 0.00268, last updated loss 0.00115\n",
      "Epoch: 187, loss 0.0010928301647251764, diff 0.00268, last updated loss 0.00115\n",
      "Epoch: 188, loss 0.0010899145854031097, diff 0.00268, last updated loss 0.00115\n",
      "Epoch: 189, loss 0.0010870094632725064, diff 0.00267, last updated loss 0.00115\n",
      "Epoch: 190, loss 0.0010841153049869865, diff 0.00267, last updated loss 0.00115\n",
      "Epoch: 191, loss 0.0010812327295450332, diff 0.00267, last updated loss 0.00115\n",
      "Epoch: 192, loss 0.0010783624556321867, diff 0.00266, last updated loss 0.00115\n",
      "Epoch: 193, loss 0.001075505288164094, diff 0.00266, last updated loss 0.00115\n",
      "Epoch: 194, loss 0.0010726621042599727, diff 0.00265, last updated loss 0.00115\n",
      "Epoch: 195, loss 0.001069833838885879, diff 0.00264, last updated loss 0.00115\n",
      "Epoch: 196, loss 0.0010670214704083096, diff 0.00264, last updated loss 0.00115\n",
      "Epoch: 197, loss 0.0010642260062924758, diff 0.00263, last updated loss 0.00115\n",
      "Epoch: 198, loss 0.0010614484691664843, diff 0.00262, last updated loss 0.00115\n",
      "Epoch: 199, loss 0.0010586898834527038, diff 0.00261, last updated loss 0.00115\n",
      "Epoch: 200, loss 0.0010559512627442676, diff 0.00259, last updated loss 0.00115\n",
      "Epoch: 201, loss 0.0010532335980769426, diff 0.00258, last updated loss 0.00115\n",
      "Model conversion not sufficient, updating...\n",
      "Last updated loss: 0.001153557604135524\n",
      "Model structure is now:\n",
      "Layer 1\n",
      "Weights matrix shape: (12,6)\n",
      "Bias vector shape (12,1)\n",
      "Layer 2\n",
      "Weights matrix shape: (1,12)\n",
      "Bias vector shape (1,1)\n",
      "Epoch: 202, loss 0.0010505378472179883, diff 0.00257, last updated loss 0.00105\n",
      "Epoch: 203, loss 0.0010480975685981373, diff 0.00233, last updated loss 0.00105\n",
      "Epoch: 204, loss 0.0010454481563987636, diff 0.00253, last updated loss 0.00105\n",
      "Epoch: 205, loss 0.0010428084231804632, diff 0.00253, last updated loss 0.00105\n",
      "Epoch: 206, loss 0.001040194683126526, diff 0.00251, last updated loss 0.00105\n",
      "Epoch: 207, loss 0.0010376075757786984, diff 0.00249, last updated loss 0.00105\n",
      "Epoch: 208, loss 0.0010350477047368959, diff 0.00247, last updated loss 0.00105\n",
      "Epoch: 209, loss 0.0010325155952769249, diff 0.00245, last updated loss 0.00105\n",
      "Epoch: 210, loss 0.00103001168687171, diff 0.00243, last updated loss 0.00105\n",
      "Epoch: 211, loss 0.0010275363360117832, diff 0.00241, last updated loss 0.00105\n",
      "Epoch: 212, loss 0.0010250898194906352, diff 0.00239, last updated loss 0.00105\n",
      "Epoch: 213, loss 0.0010226723373528352, diff 0.00236, last updated loss 0.00105\n",
      "Epoch: 214, loss 0.0010202840158859865, diff 0.00234, last updated loss 0.00105\n",
      "Epoch: 215, loss 0.0010179249109385298, diff 0.00232, last updated loss 0.00105\n",
      "Epoch: 216, loss 0.00101559501166567, diff 0.00229, last updated loss 0.00105\n",
      "Epoch: 217, loss 0.0010132942446925306, diff 0.00227, last updated loss 0.00105\n",
      "Epoch: 218, loss 0.0010110224786237367, diff 0.00225, last updated loss 0.00105\n",
      "Epoch: 219, loss 0.0010087795288008835, diff 0.00222, last updated loss 0.00105\n",
      "Epoch: 220, loss 0.0010065651621995481, diff 0.00220, last updated loss 0.00105\n",
      "Epoch: 221, loss 0.0010043791023585374, diff 0.00218, last updated loss 0.00105\n",
      "Epoch: 222, loss 0.0010022210342412227, diff 0.00215, last updated loss 0.00105\n",
      "Epoch: 223, loss 0.0010000906089409033, diff 0.00213, last updated loss 0.00105\n",
      "Epoch: 224, loss 0.000997987448156801, diff 0.00211, last updated loss 0.00105\n",
      "Epoch: 225, loss 0.0009959111483842907, diff 0.00208, last updated loss 0.00105\n",
      "Epoch: 226, loss 0.0009938612847808974, diff 0.00206, last updated loss 0.00105\n",
      "Epoch: 227, loss 0.000991837414687503, diff 0.00204, last updated loss 0.00105\n",
      "Epoch: 228, loss 0.0009898390808011778, diff 0.00202, last updated loss 0.00105\n",
      "Epoch: 229, loss 0.000987865814011334, diff 0.00200, last updated loss 0.00105\n",
      "Epoch: 230, loss 0.0009859171359230098, diff 0.00198, last updated loss 0.00105\n",
      "Model conversion not sufficient, updating...\n",
      "Last updated loss: 0.0010505378472179883\n",
      "Model structure is now:\n",
      "Layer 1\n",
      "Weights matrix shape: (13,6)\n",
      "Bias vector shape (13,1)\n",
      "Layer 2\n",
      "Weights matrix shape: (1,13)\n",
      "Bias vector shape (1,1)\n",
      "Epoch: 231, loss 0.0009839925611002576, diff 0.00196, last updated loss 0.00098\n",
      "Epoch: 232, loss 0.0009823191639337142, diff 0.00170, last updated loss 0.00098\n",
      "Epoch: 233, loss 0.000980444986329354, diff 0.00191, last updated loss 0.00098\n",
      "Epoch: 234, loss 0.0009785841837165023, diff 0.00190, last updated loss 0.00098\n",
      "Epoch: 235, loss 0.0009767456486426298, diff 0.00188, last updated loss 0.00098\n",
      "Epoch: 236, loss 0.0009749289709673232, diff 0.00186, last updated loss 0.00098\n",
      "Epoch: 237, loss 0.0009731337135200978, diff 0.00184, last updated loss 0.00098\n",
      "Epoch: 238, loss 0.0009713594101606631, diff 0.00183, last updated loss 0.00098\n",
      "Epoch: 239, loss 0.0009696055789493709, diff 0.00181, last updated loss 0.00098\n",
      "Epoch: 240, loss 0.0009678717339950643, diff 0.00179, last updated loss 0.00098\n",
      "Epoch: 241, loss 0.0009661573923858901, diff 0.00177, last updated loss 0.00098\n",
      "Epoch: 242, loss 0.0009644620779838588, diff 0.00176, last updated loss 0.00098\n",
      "Epoch: 243, loss 0.0009627853235849874, diff 0.00174, last updated loss 0.00098\n",
      "Epoch: 244, loss 0.0009611266722587386, diff 0.00173, last updated loss 0.00098\n",
      "Epoch: 245, loss 0.0009594856782605991, diff 0.00171, last updated loss 0.00098\n",
      "Epoch: 246, loss 0.0009578619076999191, diff 0.00170, last updated loss 0.00098\n",
      "Epoch: 247, loss 0.00095625493904551, diff 0.00168, last updated loss 0.00098\n",
      "Epoch: 248, loss 0.0009546643635068402, diff 0.00167, last updated loss 0.00098\n",
      "Epoch: 249, loss 0.000953089785309247, diff 0.00165, last updated loss 0.00098\n",
      "Epoch: 250, loss 0.0009515308218743444, diff 0.00164, last updated loss 0.00098\n",
      "Epoch: 251, loss 0.000949987103914273, diff 0.00162, last updated loss 0.00098\n",
      "Epoch: 252, loss 0.0009484582754479302, diff 0.00161, last updated loss 0.00098\n",
      "Epoch: 253, loss 0.0009469439937475366, diff 0.00160, last updated loss 0.00098\n",
      "Epoch: 254, loss 0.0009454439292239179, diff 0.00159, last updated loss 0.00098\n",
      "Epoch: 255, loss 0.0009439577652589427, diff 0.00157, last updated loss 0.00098\n",
      "Epoch: 256, loss 0.0009424851979932736, diff 0.00156, last updated loss 0.00098\n",
      "Epoch: 257, loss 0.0009410259360771688, diff 0.00155, last updated loss 0.00098\n",
      "Epoch: 258, loss 0.000939579700391398, diff 0.00154, last updated loss 0.00098\n",
      "Epoch: 259, loss 0.0009381462237448748, diff 0.00153, last updated loss 0.00098\n",
      "Epoch: 260, loss 0.0009367252505546302, diff 0.00152, last updated loss 0.00098\n",
      "Epoch: 261, loss 0.0009353165365132721, diff 0.00151, last updated loss 0.00098\n",
      "Model conversion not sufficient, updating...\n",
      "Last updated loss: 0.0009839925611002576\n",
      "Model structure is now:\n",
      "Layer 1\n",
      "Weights matrix shape: (14,6)\n",
      "Bias vector shape (14,1)\n",
      "Layer 2\n",
      "Weights matrix shape: (1,14)\n",
      "Bias vector shape (1,1)\n",
      "Epoch: 262, loss 0.0009339198482481514, diff 0.00150, last updated loss 0.00093\n",
      "Epoch: 263, loss 0.0009327539084645305, diff 0.00125, last updated loss 0.00093\n",
      "Epoch: 264, loss 0.000931384044094845, diff 0.00147, last updated loss 0.00093\n",
      "Epoch: 265, loss 0.0009300203716930751, diff 0.00147, last updated loss 0.00093\n",
      "Epoch: 266, loss 0.000928667722083078, diff 0.00146, last updated loss 0.00093\n",
      "Epoch: 267, loss 0.0009273260297288515, diff 0.00145, last updated loss 0.00093\n",
      "Epoch: 268, loss 0.0009259951960459745, diff 0.00144, last updated loss 0.00093\n",
      "Epoch: 269, loss 0.0009246750928623518, diff 0.00143, last updated loss 0.00093\n",
      "Epoch: 270, loss 0.0009233655778446765, diff 0.00142, last updated loss 0.00093\n",
      "Epoch: 271, loss 0.000922066505789431, diff 0.00141, last updated loss 0.00093\n",
      "Epoch: 272, loss 0.0009207777343460849, diff 0.00140, last updated loss 0.00093\n",
      "Epoch: 273, loss 0.0009194991265315316, diff 0.00139, last updated loss 0.00093\n",
      "Epoch: 274, loss 0.0009182305516844267, diff 0.00138, last updated loss 0.00093\n",
      "Epoch: 275, loss 0.0009169718857095331, diff 0.00137, last updated loss 0.00093\n",
      "Epoch: 276, loss 0.0009157230110133629, diff 0.00136, last updated loss 0.00093\n",
      "Epoch: 277, loss 0.0009144838163132035, diff 0.00136, last updated loss 0.00093\n",
      "Epoch: 278, loss 0.0009132541963995472, diff 0.00135, last updated loss 0.00093\n",
      "Epoch: 279, loss 0.000912034051885955, diff 0.00134, last updated loss 0.00093\n",
      "Epoch: 280, loss 0.0009108232889596405, diff 0.00133, last updated loss 0.00093\n",
      "Epoch: 281, loss 0.0009096218191376264, diff 0.00132, last updated loss 0.00093\n",
      "Epoch: 282, loss 0.0009084295590294583, diff 0.00131, last updated loss 0.00093\n",
      "Epoch: 283, loss 0.000907246430106289, diff 0.00130, last updated loss 0.00093\n",
      "Epoch: 284, loss 0.0009060723584757327, diff 0.00130, last updated loss 0.00093\n",
      "Epoch: 285, loss 0.0009049072746615865, diff 0.00129, last updated loss 0.00093\n",
      "Epoch: 286, loss 0.0009037511133880871, diff 0.00128, last updated loss 0.00093\n",
      "Epoch: 287, loss 0.0009026038133679457, diff 0.00127, last updated loss 0.00093\n",
      "Epoch: 288, loss 0.0009014653170938691, diff 0.00126, last updated loss 0.00093\n",
      "Epoch: 289, loss 0.0009003355706332001, diff 0.00125, last updated loss 0.00093\n",
      "Epoch: 290, loss 0.0008992145234254593, diff 0.00125, last updated loss 0.00093\n",
      "Epoch: 291, loss 0.0008981021280824752, diff 0.00124, last updated loss 0.00093\n",
      "Epoch: 292, loss 0.0008969983401911101, diff 0.00123, last updated loss 0.00093\n",
      "Epoch: 293, loss 0.0008959031181182663, diff 0.00122, last updated loss 0.00093\n",
      "Epoch: 294, loss 0.0008948164228182762, diff 0.00121, last updated loss 0.00093\n",
      "Model conversion not sufficient, updating...\n",
      "Last updated loss: 0.0009339198482481514\n",
      "Model structure is now:\n",
      "Layer 1\n",
      "Weights matrix shape: (15,6)\n",
      "Bias vector shape (15,1)\n",
      "Layer 2\n",
      "Weights matrix shape: (1,15)\n",
      "Bias vector shape (1,1)\n",
      "Epoch: 295, loss 0.0008937382176424053, diff 0.00121, last updated loss 0.00089\n",
      "Epoch: 296, loss 0.0008928765672614784, diff 0.00097, last updated loss 0.00089\n",
      "Epoch: 297, loss 0.0008918172060230409, diff 0.00119, last updated loss 0.00089\n",
      "Epoch: 298, loss 0.0008907640014253706, diff 0.00118, last updated loss 0.00089\n",
      "Epoch: 299, loss 0.0008897189408169536, diff 0.00117, last updated loss 0.00089\n"
     ]
    }
   ],
   "source": [
    "# initialize a list to store the loss value for each epoch\n",
    "lossHistory = []\n",
    "\n",
    "# Approx. control\n",
    "alpha = 0.05\n",
    "batchSize = 1\n",
    "num_epochs = 300\n",
    "threshold = 0.02\n",
    "\n",
    "# layerSizes = [300, 1]\n",
    "layerSizes = [5, 1]\n",
    "\n",
    "converter = BasicConverter(num_epochs=num_epochs, batch_size=batchSize, learning_rate=alpha, threshold=threshold)\n",
    "\n",
    "datasize = len(train)\n",
    "\n",
    "# convert features and outputs to np array\n",
    "train = np.array(train)\n",
    "\n",
    "# shuffle signal and background\n",
    "s = np.arange(train.shape[0])\n",
    "np.random.shuffle(s)\n",
    "train = train[s]\n",
    "\n",
    "# Initialise model\n",
    "model = BaseModel(len(train[0]), 1)\n",
    "modelloc = 'approx_B_temp.pkl'\n",
    "histloc = 'approx_B_temp_history.pkl'\n",
    "\n",
    "if os.path.exists(modelloc):\n",
    "    print (\"Model found, loading\")\n",
    "    model.load_model(modelloc)\n",
    "    [losses, diffs, updates] = joblib.load(histloc)\n",
    "else:\n",
    "    if len(layerSizes) == 1:\n",
    "        model.add_layer(1)\n",
    "    else:\n",
    "        for l in layerSizes:\n",
    "            model.add_layer(l)\n",
    "\n",
    "    model.print_layers()\n",
    "\n",
    "    print(\"Starting stochastic conversion...\")\n",
    "    converter.convert_model(model, classifier, train)\n",
    "    losses = converter.losses()\n",
    "    diffs = converter.diffs()\n",
    "    updates = converter.updates()\n",
    "\n",
    "    model.save_model(modelloc)\n",
    "\n",
    "    f_train = open(histloc, 'wb')\n",
    "    training_data = [losses, diffs, updates]\n",
    "    pickle.dump(training_data, f_train)\n",
    "    f_train.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add original decisions and drone decisions to dataframes\n",
    "from copy import deepcopy\n",
    "import time\n",
    "def addProbs(df, cl, drone):\n",
    "    df_ret = deepcopy(df)\n",
    "    df_ret['prob_orig']= df.apply(lambda x: float(cl.predict_proba(np.expand_dims(x.reshape(1, -1), axis=2))[0]), axis=1)\n",
    "    df_ret['prob_drone']= df.apply(lambda x: float(drone.evaluate_total(x, debug=False)), axis=1)\n",
    "    return df_ret\n",
    "def addProbs_l(l, cl, drone):\n",
    "    print (\"Adding %s probs\" % len(l))\n",
    "    p_orig = []\n",
    "    p_drone = []\n",
    "    start = time.clock()\n",
    "    for x in l:\n",
    "        p_orig.append(cl.predict_proba(np.expand_dims(x.reshape(1, -1), axis=2))[0].tolist()[0])\n",
    "    diff = time.clock()-start\n",
    "    print (\"Original: Took %s seconds to evaluate %s calls: %.8f s/call\" %(diff, len(l), diff/float(len(l))))\n",
    "    start = time.clock()\n",
    "    for x in l:\n",
    "        p_drone.append(drone.evaluate_total(np.expand_dims(x.reshape(1, -1), axis=2), debug=False).tolist()[0][0])\n",
    "    diff = time.clock()-start\n",
    "    print (\"Drone: Took %s seconds to evaluate %s calls: %.8f s/call\" %(diff, len(l), diff/float(len(l))))\n",
    "    return p_orig, p_drone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scanPoint(cutVal, sig, bkg, pname):\n",
    "    totSig = len(sig)\n",
    "    totBKG = len(bkg)\n",
    "    sig_pass = len(sig.loc[sig[pname] > cutVal])\n",
    "    bkg_rej = len(bkg.loc[bkg[pname] < cutVal])\n",
    "    bkg_pass = len(bkg.loc[bkg[pname] > cutVal])\n",
    "    eff_sig = float(sig_pass)/float(totSig)\n",
    "    rej_bkg = float(bkg_rej)/float(totBKG)\n",
    "    return eff_sig, rej_bkg, sig_pass, bkg_pass\n",
    "def scanPoint_l(cutVal, sig, bkg):\n",
    "    totSig = len(sig)\n",
    "    totBKG = len(bkg)\n",
    "    sig_pass = len([s for s in sig if s > cutVal])\n",
    "    bkg_rej = len([b for b in bkg if b < cutVal])\n",
    "    bkg_pass = len([b for b in bkg if b > cutVal])\n",
    "    eff_sig = float(sig_pass)/float(totSig)\n",
    "    rej_bkg = float(bkg_rej)/float(totBKG)\n",
    "    return eff_sig, rej_bkg, sig_pass, bkg_pass\n",
    "def prepPlot(_ax, xtitle, ytitle):\n",
    "    _ax.grid(False)\n",
    "    _ax.set_xlabel(xtitle)\n",
    "    _ax.set_ylabel(ytitle)\n",
    "    _ax.set_title(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 5000 probs\n",
      "Original: Took 2.232748000000015 seconds to evaluate 5000 calls: 0.00044655 s/call\n",
      "Drone: Took 0.2266779999999926 seconds to evaluate 5000 calls: 0.00004534 s/call\n",
      "Adding 5000 probs\n",
      "Original: Took 2.083099999999945 seconds to evaluate 5000 calls: 0.00041662 s/call\n",
      "Drone: Took 0.21591300000000047 seconds to evaluate 5000 calls: 0.00004318 s/call\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEKCAYAAADq59mMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRKbkISIikSl5iIhIZEoeIiIS2f8HTna7n9pS1DIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13cb700b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make outputs\n",
    "sig_tst_o, sig_tst_d = addProbs_l(sigTest, classifier, model)\n",
    "bkg_tst_o, bkg_tst_d = addProbs_l(bgTest, classifier, model)\n",
    "\n",
    "bins_pr = np.linspace(0, 1, 50)\n",
    "fig, ax1 = plt.subplots()\n",
    "h_sig_drone = plt.hist(np.array(sig_tst_d), fill=False, edgecolor = 'red', bins = bins_pr, alpha=0.5, label=\"sig. drone\", histtype='step')\n",
    "h_sig_test = plt.hist(np.array(sig_tst_o), fill=False, edgecolor = 'blue', bins = bins_pr, alpha=0.5, label=\"sig. test\", histtype='step')\n",
    "h_bkg_drone = plt.hist(np.array(bkg_tst_d), edgecolor = 'green', fill=False, bins = bins_pr, alpha=0.5, label=\"bkg drone\", histtype='step')\n",
    "h_bkg_test = plt.hist(np.array(bkg_tst_o), fill=False, edgecolor = 'purple', bins = bins_pr, alpha=0.5, label=\"bkg test\", histtype='step')\n",
    "prepPlot(ax1, \"Classifier prob.\", \"Candidates\")\n",
    "plt.legend()\n",
    "plt.savefig('figs/output_comp_drone.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHVJJREFUeJzt3X2cVnWd//HXe2aAERAlGdRAREtBQ5Rx8AYVsR7lzUMw\nzdbUVXQz2uq3ZrVr6W+VyrW21Vpb/ZlLhuhmur9SKc2KzDWgNAV/aKYYWqjjHXcCDjDAzHx+f5wz\nF8PNzFzAdc41N+/n43Ee17n5Xud8vgOP87nO+Z7v9ygiMDMzA6godwBmZtZ1OCmYmVmBk4KZmRU4\nKZiZWYGTgpmZFTgpmJlZgZOCmZkVOCmYmVmBk4KZmRVUlTuAnTVkyJAYOXJkucMwM+tWFi5cuCIi\najorl1lSkDQTOBNYFhFjdrB9EvBT4K/pqvsj4uud7XfkyJEsWLCglKGamfV4kl4pplyWVwqzgFuA\nuzooMy8izswwBjMz2wmZtSlExFxgVVb7NzOz0it3Q/MESc9K+oWkD5Q5FjOzXq+cDc1PAyMiokHS\nGcBs4JAdFZQ0DZgGMGLEiO22b968mfr6ehobGzMMt3urrq5m+PDh9OnTp9yhmFkXVrakEBFr28w/\nLOlWSUMiYsUOys4AZgDU1dVt9wKI+vp69txzT0aOHImkTOPujiKClStXUl9fz0EHHVTucMysCyvb\n7SNJ+yk9g0s6Jo1l5a7sq7GxkX322ccJoR2S2GeffXwlZWadyvKR1HuAScAQSfXAdKAPQETcBpwL\nfEZSE7AB+ETsxmvgnBA65r+PmRUjs6QQEed3sv0WkkdWzcysE1/7GkyYAB/+cLbHKffTR73OGWec\nwerVqzssc+211/LII4/s0v4fe+wxzjzTXT/MeppvfAMefTT743S7YS66q4ggInj44Yc7Lfv1r3fa\nsdvMLBO+Uiih73znO4wZM4YxY8Zw0003sXTpUkaNGsXFF1/MmDFjeO211xg5ciQrViQPWF133XWM\nGjWKE088kfPPP58bb7wRgEsuuYSf/OQnQDKsx/Tp06mtreWII45g8eLFADz55JMcf/zxjBs3jgkT\nJvDiiy+Wp9Jm1qP0vCuFK66ARYtKu8+jjoKbbuqwyMKFC7njjjv4wx/+QERw7LHHcvLJJ7NkyRLu\nvPNOjjvuuK3KP/XUU9x3330888wzbN68mdraWo4++ugd7nvIkCE8/fTT3Hrrrdx4443cfvvtjB49\nmnnz5lFVVcUjjzzC1VdfzX333VeyKptZ79TzkkKZzJ8/n7PPPpsBAwYAcM455zBv3jwOPPDA7RIC\nwO9+9zvOOussqqurqa6uZvLkye3u+5xzzgHg6KOP5v777wdgzZo1TJ06lSVLliCJzZs3Z1ArM+tt\nel5S6OQXfd5ak8Tu6NevHwCVlZU0NTUBcM0113DKKafwwAMPsHTpUiZNmrTbxzEzc5tCiZx00knM\nnj2b9evXs27dOh544AFOOumkdsufcMIJPPjggzQ2NtLQ0MBDDz20U8dbs2YNw4YNA2DWrFm7E7qZ\nWYGTQonU1tZyySWXcMwxx3Dsscdy2WWXMXjw4HbLjx8/nilTpjB27FhOP/10jjjiCPbaa6+ij3fl\nlVdy1VVXMW7cuMLVg5nZ7tJudCIui7q6utj2JTsvvPAChx12WJki2nUNDQ0MHDiQ9evXM3HiRGbM\nmEFtbW1mx+uufyczg3794ItfhG9+c9e+L2lhRNR1Vq7ntSl0I9OmTeP555+nsbGRqVOnZpoQzMyK\n4aRQRj/60Y/KHYKZdRN53dRxm4KZWTeRx7iWTgpmZlbgpGBmZgVOCmZmVuCkkJGvfvWrhQHuzMy6\nCyeFHLmTmZl1dU4KJXT99ddz6KGHcuKJJxaGsp40aRJXXHEFdXV1fPe732Xp0qV88IMfZOzYsXzo\nQx/i1VdfBZLhsi+//HImTJjAwQcfXBg6G+CGG25g/PjxjB07lunTp5elbmbWO/S4fgplGjmbhQsX\ncu+997Jo0SKampq2Ggp706ZNtPbCnjx5MlOnTmXq1KnMnDmTyy+/nNmzZwPw5ptvMn/+fBYvXsyU\nKVM499xzmTNnDkuWLOHJJ58kIpgyZQpz585l4sSJpa2kmRm+UiiZefPmcfbZZ9O/f38GDRrElClT\nCtvOO++8wvzjjz/OBRdcAMBFF13E/PnzC9s++tGPUlFRweGHH87bb78NwJw5c5gzZw7jxo2jtraW\nxYsXs2TJkpxqZWa9TY+7UuhiI2cDxQ+f3TpENiSv72z9vOqqq/j0pz+dSWxmZm35SqFEJk6cyOzZ\ns9mwYQPvvvsuDz744A7LTZgwgXvvvReAu+++u8PhtQFOPfVUZs6cSUNDAwCvv/46y5YtK23wZmap\nHnelUC61tbWcd955HHnkkQwdOpTx48fvsNzNN9/MpZdeyg033EBNTQ133HFHh/v9yEc+wgsvvMDx\nxx8PwMCBA/nhD3/I0KFDS14HM+u68hr7yENn9yL+O5l1X336wJVXwvXX79r3ix0627ePzMyswEnB\nzMwKekxS6G63wfLmv4+ZFaNHJIXq6mpWrlzpE187IoKVK1dSXV1d7lDMrIvrEU8fDR8+nPr6epYv\nX17uULqs6upqhg8fXu4wzKyL6xFJoU+fPhx00EHlDsPMrNvrEbePzMysNJwUzMysILOkIGmmpGWS\nnuuk3HhJTZLOzSoWMzMrTpZXCrOA0zoqIKkS+BYwJ8M4zMy6vbwerswsKUTEXGBVJ8X+AbgP8Ahv\nZmadkLI/RtnaFCQNA84GvldE2WmSFkha4MdOzcyyU86G5puAL0dES2cFI2JGRNRFRF1NTU0OoZmZ\n9U7l7KdQB9yr5HpoCHCGpKaImF3GmMzMerWyJYWIKPQ2kzQLeMgJwcysvDJLCpLuASYBQyTVA9OB\nPgARcVtWxzUzs12XWVKIiPN3ouwlWcVhZmbFc49mMzMrcFIwM7MCJwUzMytwUjAz6wa6/TAXZmZW\nWj16mAszM+t6nBTMzKzAScHMzAqcFMzMrMBJwczMCpwUzMyswEnBzMwKdikpSKotdSBmZlZ+u3ql\n8JmSRmFmZl3CLiWFiPhUqQMxM7P25TXMRbvvU5A0OiIWt3OrKIBVEfFKdqGZmVlbeQxz0dFLdr4I\nTAO+3c72fSQ9ExEXlT4sMzMrh3aTQkRMSz9Paa+MpDlZBGVmZuXRaZuCpP6S/lnSjHT5EElnAkTE\nR7IO0MzM8lNMQ/MdwCZgQrr8OvAvmUVkZmZlU0xSeF9E/BuwGSAi1gM5NHeYmVneikkKmyTtQfLE\nEZLeB2zMNCozMyuLjp4+ajUd+CVwgKS7gROAS7IMyszMyqPDpCBJwGLgHOA4kttGn4+IFTnEZmZm\nOeswKURESHo4Io4Afp5TTGZmVibFtCk8LWl85pGYmVnZFdOmcCxwoaRXgHUkt5AiIsZmGpmZmRWU\nfeyjNk7NPAozM+tUucc+AsCD3pmZ9R5+85qZmRU4KZiZWUFmSUHSTEnLJD3XzvazJD0raZGkBZJO\nzCoWMzMrTkcv2XmXdGiLHYmIQZ3sexZwC3BXO9t/A/ws7QsxFvi/wOhO9mlmZhnq6H0KewJIug54\nE/gvksdRLwT272zHETFX0sgOtje0WRxABwnIzMzyUcztoykRcWtEvBsRayPie8BZpTi4pLMlLSbp\nLf13pdinmZntumKSwjpJF0qqlFQh6UKSTmy7LSIeiIjRwEeB69orJ2la2u6wYPny5aU4tJmZ7UAx\nSeEC4G+At9Pp4+m6komIucDBkoa0s31GRNRFRF1NTU0pD21mZm0U03ltKSW6XdSWpPcDL6cNzbVA\nP2BlqY9jZmbF6zQpSKoBPgWMbFs+IjpsA5B0DzAJGCKpnuS9DH3S794GfAy4WNJmYANwXkReo3uY\nmXU/XWKYC+CnwDzgEaC52B1HxPmdbP8W8K1i92dmZtkrJin0j4gvZx6JmZmVXTENzQ9JOiPzSMzM\nrOyKSQqfJ0kMGyStlfSupLVZB2ZmZtt4443MD1HM00d7Zh6FmZl17vnngfdmeohinj6auKP1ad8C\nMzPrQYppaP6nNvPVwDHAQuCDmURkZmZlU8zto8ltlyUdANyUWURmZlY2u/I+hXrgsFIHYmZm5VdM\nm8LNbBnWugI4Cng6y6DMzGyLwlgPOXRpLqZNYUGb+Sbgnoj4XUbxmJlZO5TDa2eKaVO4U1Jf4NB0\n1YvZhmRmZuVSzO2jScCdwFKSN68dIGmqH0k1M+t5irl99G3gIxHxIoCkQ4F7gKOzDMzMzPJXzNNH\nfVoTAkBE/Jl0CGwzM8tRV2lolnQ78MN0+UK2bnw2M7Meopik8Bngc8Dl6fI84NbMIjIzs7LpMClI\nqgRmRsSFwHfyCcnMzMqlwzaFiGgGDkwfSTUzsx6umNtHfwF+J+lnwLrWlRHhKwczsx6mmKTwcjpV\nAH63gplZziL7jswFxfRo/loegZiZWcdyeCK1qB7ND8J2A26sIXks9T8jojGLwMzMLH/FdF77C9AA\nfD+d1gLvkoyF9P3sQjMzs7wV06YwISLGt1l+UNJTETFe0p+yCszMzPJXzJXCQEkjWhfS+YHp4qZM\nojIzs7Io5krhS8B8SS+TjJJ6EPBZSQNIRk81M7Meopik8AvgEGB0uvwiEBGxEb+r2cysRynm9tEP\nImJjRDwTEc8AlcDDGcdlZmZlUExSeF3SrQCSBgO/ZsuIqWZmlpccOip0mhQi4hqgQdJtwBzg2xFx\nR+aRmZlZ7tptU5B0TpvFPwDXAE8CIemciLg/6+DMzCxfHTU0T95m+f+RvHFtMkkPZycFM7McdImx\njyLi0t3ZsaSZwJnAsogYs4PtFwJfJnnM9V3gM2lDtpmZ7YC2G3Go9DptU5B0p6S92ywPTk/4nZkF\nnNbB9r8CJ0fEEcB1wIwi9mlmZhkq5umjsRGxunUhIt4BxnX2pYiYC6zqYPvv030BPAEMLyIWM7Pe\nqys8fQRUpI+iAiDpPRTX6W1nfJKkk5yZmZVRMSf3bwOPS/oxyf3/c4HrSxWApFNIksKJHZSZBkwD\nGDFiRHvFzMxsNxXTT+Eu4GPA28BbwDkR8V+lOLikscDtwFkRsbKDGGZERF1E1NXU1JTi0GZmtgNF\n3QaKiD9JWg5UQzJSakS8ujsHTkdbvR+4KCL+vDv7MjOz0ijmzWtTSG4hvRdYBhwIvAB8oJPv3QNM\nAoZIqgemk/RzICJuA64F9gFuVdJ40hQRdbtaETMz233FXClcBxwHPBIR49I2gL/t7EsRcX4n2y8D\nLisqSjMzy0UxTx9tTu/3V0iqiIj/AfyL3sysByrmSmG1pIHAXOBuScuAddmGZWZmrfIc5qKYK4Wz\ngPXAF4BfAi+z/bhIZmaWlTQr5NB3rfMrhYhovSpokfRzYGVEnnnLzMzy0u6VgqTjJD0m6X5J4yQ9\nBzwHvC2pozGNzMysm+roSuEW4GpgL+BR4PSIeELSaOAekltJZmbWg3TUplAVEXMi4sfAWxHxBEBE\nLM4nNDMzy1tHSaGlzfyGbba5TcHMLC85NuN2dPvoSElrSQbB2yOdJ12uzjwyMzPbWg6PH3X05rXK\nzI9uZmZdSjH9FMzMrJdwUjAzswInBTOzLi5a8mto7qjz2q8kfSHtl2BmZmWWxzAXHV0pTAXeAb4q\n6WlJ35N0lqQB2YdlZmbl0NHTR28Bs4BZkiqAY4HTgSslbQDmRMS/5RKlmZnlotjXcbYAj6fTtZKG\nAKdmGZiZmeWvqKSwrYhYAdxd4ljMzGxHcuzR7KePzMyswEnBzMwKdikpSLq01IGYmVn57eqVwtdK\nGoWZmXUJ7TY0S3q2vU3AvtmEY2Zm2+kiQ2fvS/LY6TvbrBfw+8wiMjOzrRRyQjmHzgYeAgZGxKJt\nN0h6LLOIzMxsh5TD+8066tH8yQ62XZBNOGZmVk5+JNXMzAqcFMzMujr3aDYzs+3k0NDspGBmZgVO\nCmZmVuCkYGZmBZklBUkzJS2T9Fw720dLelzSRkn/mFUcZmbdXg9paJ4FnNbB9lXA5cCNGcZgZtZz\nlPkdzbslIuaSnPjb274sIp4CNmcVg5mZ7Zxu0aYgaZqkBZIWLF++vNzhmJnlKse7R90jKUTEjIio\ni4i6mpqacodjZlYWOdw96h5JwcysV9uc3mV35zUzM2PNmuRzj+rMD9XR0Nm7RdI9wCRgiKR6YDrQ\nByAibpO0H7AAGAS0SLoCODwi1mYVk5lZt9R6pVBZmfmhMksKEXF+J9vfAoZndXwzsx6jqSn5rMg+\nKfj2kZlZV9fYmHz2yex3fIGTgplZV7c2vaveL/s2BScFM7OurqEh+ezbN/NDOSmYmXV1rb3X/Eiq\nmZk5KZiZWcHahuRUvWadG5rNzHq9FauTZHDYwRszP5aTgplZF9fclNw+6r9H9iPjOSmYmXVxTc1J\nW0JlldsUzMx6vdYrhcrsmxScFMzMurrmN94GoDKHM7aTgplZF/f25vcAUDNij8yP5aRgZtbFvbW6\nHwD7DfOAeGZm1pK0KVT1zf6U7aRgZtbVRUvyWeGkYGbW661vTG8b5fCSHScFM7MubvHbezOABvbb\n3/0UzMx6vd88W8PerKZy0IDMj+WkYGbWxb3ZOJi+bPIoqWZmBv0rNzKielkux3JSMDPrwhobYU3T\nAI7e741cjuekYGbWhb32GmyMfhy59yu5HM9JwcysC3v0180ADFpbn8vxnBTMzLqwv/9c0jfhmInV\nuRzPScHMrIt69IE1AIzkr7z3sx/N5ZhOCmZmXVAE/M0nkkdQH/zwzTB+fC7HdVIwM+uCvvSFFlZu\nGgTA4T+/IbfjOimYmXUxv/0t/Pt3k9Pzqht+QEWf7Mc8auWkYGZWZo2N8PTTMH160ml50qRk/dIP\nf4rBX/q7XGPJ4Y2fZmbWVnMzzJ8PixfD1VfDqlVbtr1PLzM8XuP/7PcvHHj7zFyGtmjLScHMLAdz\n58IvfgHLl8N998Hq1cn6/Qc1cOCgzXzloP/mlGf+nVHxZ/jmN+EffwlV+Z+iMzuipJnAmcCyiBiz\ng+0CvgucAawHLomIp7OKx8ys1FpaYNkyeOMNeP31rae33oK1a+Hdd+Gdd5KeyQA172ni/RWv8uFB\nD3PJ2v/g/WtfoqKqEjYcDOcfDV/5MYwdW7Y6ZZmGZgG3AHe1s/104JB0Ohb4XvppZrbbWlpg/XpY\nty75bE46BhMBGzYk6xsatkyNjdDUlEzNzVvm166FFStg5cpkPy0tya/8N99MpqamrY9bURHst2+w\n3+BN7BWrOShWc+Se6xj3gUVMqfw573v2AdhjD5g8GSZ8Dk47DQ49NPfbRO3JLClExFxJIzsochZw\nV0QE8ISkvSXtHxFvZhWTWXcUkUwtLcnJqqVl62ln17XdX+t822lH67dd19ICmzbB5s1bpo6Wm5q2\nj6NtjM3NW5+I284XOzU2bkkA69YFjY2lOclWVbawz4CNDBmwgf5Vm1C0sFff9YzeczXvrVnFsH7L\nGVb5NsNW/4lhrz3BvmtepOrNZmh7JuvbFw48EIYOTW4NXXop7LtvSeIrtXK2KQwDXmuzXJ+uyyQp\n/Or6BXzxur2z2LXZdiJEC6KZSlpCtFCRTNG6roIW0vVRQXOb7a1lmyP5jB70kGBr7SpppkKxZT79\nrFIzVTS1mZqpYnP62ZTOJ9v60kT/SOYraaKaRgbEOvqzjgHp1J/1hc8qtvyk34MNDKRhq6kfG7c6\ndiXNVNLMHs0b0Fpg7TaVqa5OfvG3TgccACdOhH0/niwPHZp0OBs1Cvr0yfXvvDu6RUOzpGnANIAR\nI0bs0j4G1fTj8CHLSxmWWYcq1UKFIv1MT+8KKtSSrGuzXEEUyleQfrZ+t7C8Tbk2+yj2GBUK1OZT\nCgSF+Qpa16frtiq79bq+FU30qWimj5q2zLddrmxJlquCqooWKipAlRXJbRIpeQl9lvOVlVC5N1Tu\nk84XMVVVbX2yb2++X78uc7un1MqZFF4HDmizPDxdt52ImAHMAKirq4tdOdjx047gx9N25ZtmZr1H\nOa9LfwZcrMRxwBq3J5iZlVeWj6TeA0wChkiqB6YDfQAi4jbgYZLHUV8ieST10qxiMTOz4mT59NH5\nnWwP4HNZHd/MzHZez3mswczMdpuTgpmZFTgpmJlZgZOCmZkVOCmYmVmBkoeAug9Jy4FXdvHrQ4AV\nJQynO3CdewfXuXfYnTofGBE1nRXqdklhd0haEBF15Y4jT65z7+A69w551Nm3j8zMrMBJwczMCnpb\nUphR7gDKwHXuHVzn3iHzOveqNgUzM+tYb7tSMDOzDvTIpCDpNEkvSnpJ0ld2sF2S/iPd/qyk2nLE\nWUpF1PnCtK5/lPR7SUeWI85S6qzObcqNl9Qk6dw848tCMXWWNEnSIkl/kvTbvGMstSL+b+8l6UFJ\nz6R17tYjLkuaKWmZpOfa2Z7t+SsietQEVAIvAwcDfYFngMO3KXMG8AtAwHHAH8oddw51ngAMTudP\n7w11blPuUZKh2s8td9w5/DvvDTwPjEiXh5Y77hzqfDXwrXS+BlgF9C137LtR54lALfBcO9szPX/1\nxCuFY4CXIuIvEbEJuBc4a5syZwF3ReIJYG9J++cdaAl1WueI+H1EvJMuPkHyprvurJh/Z4B/AO4D\nluUZXEaKqfMFwP0R8SpARHT3ehdT5wD2lCRgIElSaKKbioi5JHVoT6bnr56YFIYBr7VZrk/X7WyZ\n7mRn6/NJkl8a3VmndZY0DDgb+F6OcWWpmH/nQ4HBkh6TtFDSxblFl41i6nwLcBjwBvBH4PMR0ZJP\neGWR6fmrnO9otjKQdApJUjix3LHk4CbgyxHRoh76kvUdqAKOBj4E7AE8LumJiPhzecPK1KnAIuCD\nwPuAX0uaFxFryxtW99QTk8LrwAFtloen63a2THdSVH0kjQVuB06PiJU5xZaVYupcB9ybJoQhwBmS\nmiJidj4hllwxda4HVkbEOmCdpLnAkUB3TQrF1PlS4F8jueH+kqS/AqOBJ/MJMXeZnr964u2jp4BD\nJB0kqS/wCeBn25T5GXBx2op/HLAmIt7MO9AS6rTOkkYA9wMX9ZBfjZ3WOSIOioiRETES+Anw2W6c\nEKC4/9s/BU6UVCWpP3As8ELOcZZSMXV+leTKCEn7AqOAv+QaZb4yPX/1uCuFiGiS9L+AX5E8uTAz\nIv4k6e/T7beRPIlyBvASsJ7kl0a3VWSdrwX2AW5Nfzk3RTceTKzIOvcoxdQ5Il6Q9EvgWaAFuD0i\ndvhoY3dQ5L/zdcAsSX8keSLnyxHRbUdPlXQPMAkYIqkemA70gXzOX+7RbGZmBT3x9pGZme0iJwUz\nMytwUjAzswInBTMzK3BSMDOzAicF6zUk/e90FM1n01FEj03X3y7p8AyO17CT5T8u6QVJ/5Mu35PG\n+oVSx2bWnh7XT8FsRyQdD5wJ1EbERklDSEbdJCIuK2twW3wS+FREzJe0HzA+It5f7qCsd/GVgvUW\n+wMrImIjQESsiIg3ANLB4+rS+U9K+rOkJyV9X9It6fpZ6Rj2v5f0l9Z3M0gaKOk3kp5W8q6KHY3U\nuhVJf5vuf5Gk/5RUKelakvGofiDpBmAOMCwtc1ImfxGzHXBSsN5iDnBAesK/VdLJ2xaQ9F7gGpIx\n6k8gGT+nrf1JTtxnAv+armsEzo6IWuAU4NvqYPQ9SYcB5wEnRMRRQDNwYUR8HViQzv8TMAV4OSKO\nioh5u1xrs53kpGC9QkQ0kIweOg1YDvy3pEu2KXYM8NuIWBURm4Efb7N9dkS0RMTzwL7pOgHfkPQs\n8AjJEMb70r4PpXE8JWlRunzwrtfMrLTcpmC9RkQ0A48Bj6Xj5EwFZu3ELja2mW+9GriQ5G1fR0fE\nZklLgeoO9iHgzoi4aieOa5YbXylYryBplKRD2qw6Cnhlm2JPASdLGiypCvhYEbveC1iWJoRTgAM7\nKf8b4FxJQ9O43iOps++Y5cZXCtZbDARulrQ3yasaXyK5lVQQEa9L+gbJOPyrgMXAmk72ezfwYHrl\nsSD9Trsi4nlJ/wzMkVQBbAY+x/YJais9efRX61o8SqpZG5IGRkRDeqXwAMlQzQ+UOy6zvPj2kdnW\nvpo2AD8H/BXozi/lMdtpvlIwM7MCXymYmVmBk4KZmRU4KZiZWYGTgpmZFTgpmJlZgZOCmZkV/H80\ng7GCZf0OzQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13d4ccda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot ROC comparison & FoM optimisation\n",
    "eff_sig_drone = []\n",
    "eff_sig_test = []\n",
    "rej_bkg_drone = []\n",
    "rej_bkg_test = []\n",
    "#\n",
    "scanpoints = np.linspace(0.0, 0.001, 1000)\n",
    "scanpoints += np.linspace(0.001, 1.0, 1000)\n",
    "for s in scanpoints:\n",
    "    es, rb, nSig, nBKG = scanPoint_l(s, sig_tst_o, bkg_tst_o)\n",
    "    es_dr, rb_dr, nSig_dr, nBKG_dr = scanPoint_l(s, sig_tst_d, bkg_tst_d)\n",
    "    eff_sig_test.append(es)\n",
    "    rej_bkg_test.append(1/rb)\n",
    "    eff_sig_drone.append(es_dr)\n",
    "    rej_bkg_drone.append(1/rb_dr)\n",
    "\n",
    "fig, axes = plt.subplots()\n",
    "plt1 = axes.plot(eff_sig_test, rej_bkg_test, 'r-', label = 'original')\n",
    "plt2 = axes.plot(eff_sig_drone, rej_bkg_drone, 'b-', label= 'drone')\n",
    "plt.legend()\n",
    "prepPlot(axes, \"Signal eff.\", \"1 / Background rej.\")\n",
    "plt.savefig('figs/roc.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of model additions: 10\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13d606710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot difference history\n",
    "training = training_data\n",
    "count = [n for n in range(len(training[0]))]\n",
    "fig = plt.figure()\n",
    "plt.plot(count, training[1], '-')\n",
    "# Add markers where an update occurs\n",
    "markers_x = [c for c, a in zip(count, training[2]) if a == 1]\n",
    "markers_y = [d for d, a in zip(training[1], training[2]) if a == 1]\n",
    "print('Number of model additions: %s' % len(markers_x))\n",
    "plt.plot(markers_x, markers_y, 'g^')\n",
    "fig.suptitle(\"\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Iteration difference\")\n",
    "plt.yscale('log')\n",
    "plt.savefig(\"figs/diff_history.pdf\")\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "locally_connected1d_1 (Local (None, 5, 90)             1350      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 90)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30)                2730      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 4,111\n",
      "Trainable params: 4,111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(classifier.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
